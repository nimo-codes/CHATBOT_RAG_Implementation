{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9141278,"sourceType":"datasetVersion","datasetId":5521013},{"sourceId":9145675,"sourceType":"datasetVersion","datasetId":5524086},{"sourceId":9145920,"sourceType":"datasetVersion","datasetId":5524289}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\nbitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -r /kaggle/input/requirement/vllm_llama31.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade transformers\n## restart kernel after this ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\n#import chromadb\n#from chromadb.config import Settings\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:56:04.416697Z","iopub.execute_input":"2024-08-10T10:56:04.417495Z","iopub.status.idle":"2024-08-10T10:56:10.866527Z","shell.execute_reply.started":"2024-08-10T10:56:04.417464Z","shell.execute_reply":"2024-08-10T10:56:10.865463Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"token = \"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\"\nmodel_name = \"meta-llama/Meta-Llama-3.1-8B\"\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:56:13.991138Z","iopub.execute_input":"2024-08-10T10:56:13.991689Z","iopub.status.idle":"2024-08-10T10:56:14.056522Z","shell.execute_reply.started":"2024-08-10T10:56:13.991656Z","shell.execute_reply":"2024-08-10T10:56:14.055523Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# # !pip install --upgrade transformers\n# !pip install --upgrade trl\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_name,\n    token = token\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:56:18.454861Z","iopub.execute_input":"2024-08-10T10:56:18.455621Z","iopub.status.idle":"2024-08-10T10:56:18.696661Z","shell.execute_reply.started":"2024-08-10T10:56:18.455590Z","shell.execute_reply":"2024-08-10T10:56:18.695580Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed672f75aa954f9ca141c7852cb4ad81"}},"metadata":{}}]},{"cell_type":"code","source":"model = transformers.AutoModelForCausalLM.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n    use_auth_token =token\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=token)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:56:47.282679Z","iopub.execute_input":"2024-08-10T10:56:47.283725Z","iopub.status.idle":"2024-08-10T10:59:39.378957Z","shell.execute_reply.started":"2024-08-10T10:56:47.283681Z","shell.execute_reply":"2024-08-10T10:59:39.378007Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n2024-08-10 10:56:49.768496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-10 10:56:49.768622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-10 10:56:49.903025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d8c249ae9740d1a3d40ff900e94418"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076849d6406a4b8b8d3e4c556ff97ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d302c7791ecc4a699ed8a0cf9c9ad3ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230eba81db694f55b30b37e7d23bb159"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b853a9aa3edf4b319418e1df3f5d5431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abe57295cd204bb8b4e1808820e737f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491e4bd773024fb3be498dccfb535326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b58908f7bfe34872b0f8bf395389169b"}},"metadata":{}},{"name":"stderr","text":"You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61ceaf17a63c4c61a83412da0ec918a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f860140a7592469f8bf20d5cb9be40ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a9ab36b6874b48ba12029d06c4b2f7"}},"metadata":{}}]},{"cell_type":"code","source":"time_1 = time()\nquery_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n    max_length=600,\n    max_new_tokens=100,\n        device_map=\"auto\",)\ntime_2 = time()\nprint(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:13:38.693885Z","iopub.execute_input":"2024-08-10T11:13:38.694303Z","iopub.status.idle":"2024-08-10T11:13:38.702404Z","shell.execute_reply.started":"2024-08-10T11:13:38.694270Z","shell.execute_reply":"2024-08-10T11:13:38.701034Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Prepare pipeline: 0.001 sec.\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_model(tokenizer, pipeline, prompt_to_test):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\"\n        prompt_to_test: the prompt\n    Returns\n        None\n    \"\"\"\n    # adapted from https://huggingface.co/blog/llama2#using-transformers\n    time_1 = time()\n    sequences = pipeline(\n        prompt_to_test,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=600,\n    max_new_tokens = 500)\n    time_2 = time()\n    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n    for seq in sequences:\n        print(f\"Result: {seq['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:13:42.576163Z","iopub.execute_input":"2024-08-10T11:13:42.577132Z","iopub.status.idle":"2024-08-10T11:13:42.583617Z","shell.execute_reply.started":"2024-08-10T11:13:42.577094Z","shell.execute_reply":"2024-08-10T11:13:42.582377Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"What is aaruush SRM tech fest?. Give just a definition. Keep it in 100 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:13:43.232136Z","iopub.execute_input":"2024-08-10T11:13:43.232863Z","iopub.status.idle":"2024-08-10T11:13:43.802995Z","shell.execute_reply.started":"2024-08-10T11:13:43.232829Z","shell.execute_reply":"2024-08-10T11:13:43.801929Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nBoth `max_new_tokens` (=500) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Test inference: 0.566 sec.\nResult: What is aaruush SRM tech fest?. Give just a definition. Keep it in 100 words.\n","output_type":"stream"}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n\nllm(prompt=\"naman Nanda is?\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:13:43.805286Z","iopub.execute_input":"2024-08-10T11:13:43.806154Z","iopub.status.idle":"2024-08-10T11:13:53.254504Z","shell.execute_reply.started":"2024-08-10T11:13:43.806114Z","shell.execute_reply":"2024-08-10T11:13:53.253364Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nBoth `max_new_tokens` (=100) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"' 2. What is the name of the mother of Naman Nanda? 3. What is the name of the father of Naman Nanda? 4. What is the name of the sister of Naman Nanda? 5. What is the name of the brother of Naman Nanda? 6. What is the name of the wife of Naman Nanda? 7. What is the name of the son of Naman Nanda? 8. What'"},"metadata":{}}]},{"cell_type":"code","source":"loader = TextLoader(\"/kaggle/input/naman-update/resume.txt\",\n                    encoding=\"utf8\")\ndocuments = loader.load()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:26:44.784878Z","iopub.execute_input":"2024-08-10T11:26:44.785635Z","iopub.status.idle":"2024-08-10T11:26:44.805443Z","shell.execute_reply.started":"2024-08-10T11:26:44.785603Z","shell.execute_reply":"2024-08-10T11:26:44.804491Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\nall_splits = text_splitter.split_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:26:45.133337Z","iopub.execute_input":"2024-08-10T11:26:45.134293Z","iopub.status.idle":"2024-08-10T11:26:45.139273Z","shell.execute_reply.started":"2024-08-10T11:26:45.134256Z","shell.execute_reply":"2024-08-10T11:26:45.138178Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"model_name = \"sentence-transformers/all-mpnet-base-v2\"\n# model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:26:45.681384Z","iopub.execute_input":"2024-08-10T11:26:45.681760Z","iopub.status.idle":"2024-08-10T11:26:45.893756Z","shell.execute_reply.started":"2024-08-10T11:26:45.681735Z","shell.execute_reply":"2024-08-10T11:26:45.892822Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")\nfrom langchain.vectorstores import FAISS\n\nvectordb = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:26:46.244257Z","iopub.execute_input":"2024-08-10T11:26:46.244928Z","iopub.status.idle":"2024-08-10T11:26:46.437550Z","shell.execute_reply.started":"2024-08-10T11:26:46.244896Z","shell.execute_reply":"2024-08-10T11:26:46.436574Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0987f54a12c43c48bde6e8c3815d009"}},"metadata":{}}]},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm, \n    chain_type=\"stuff\", \n    retriever=retriever, \n    verbose=True,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:26:46.666681Z","iopub.execute_input":"2024-08-10T11:26:46.667354Z","iopub.status.idle":"2024-08-10T11:26:46.682627Z","shell.execute_reply.started":"2024-08-10T11:26:46.667300Z","shell.execute_reply":"2024-08-10T11:26:46.681685Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query: {query},about naman nanda\\n\")\n    time_1 = time()\n    result = qa.run(query)\n    time_2 = time()\n    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n    print(\"\\nResult: \", result)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:30:05.788509Z","iopub.execute_input":"2024-08-10T11:30:05.788922Z","iopub.status.idle":"2024-08-10T11:30:05.794785Z","shell.execute_reply.started":"2024-08-10T11:30:05.788888Z","shell.execute_reply":"2024-08-10T11:30:05.793591Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"query = \"what is his work experience?\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:30:10.333012Z","iopub.execute_input":"2024-08-10T11:30:10.333707Z","iopub.status.idle":"2024-08-10T11:30:15.797263Z","shell.execute_reply.started":"2024-08-10T11:30:10.333673Z","shell.execute_reply":"2024-08-10T11:30:15.796161Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Query: what is his work experience?,about naman nanda\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3762b232474e4c67b261fd615252541f"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nBoth `max_new_tokens` (=100) and `max_length`(=600) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 5.459 sec.\n\nResult:   \"He is currently an intern at Renault Nissan, working on creating efficient and reliable API endpoints. He is also working on a project called Firewatch, which integrates live satellite imagery for real-time data analysis.\"\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndocs = vectordb.similarity_search(query)\nprint(f\"Query: {query}\")\nprint(f\"Retrieved documents: {len(docs)}\")\nfor doc in docs:\n    doc_details = doc.to_json()['kwargs']\n    print(\"Source: \", doc_details['metadata']['source'])\n    print(\"Text: \", doc_details['page_content'], \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T11:30:02.947606Z","iopub.execute_input":"2024-08-10T11:30:02.948044Z","iopub.status.idle":"2024-08-10T11:30:02.987164Z","shell.execute_reply.started":"2024-08-10T11:30:02.948011Z","shell.execute_reply":"2024-08-10T11:30:02.986215Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305e2592b0bb452fb50ed4e014035c7f"}},"metadata":{}},{"name":"stdout","text":"Query: what is his github link?\nRetrieved documents: 4\nSource:  /kaggle/input/naman-update/resume.txt\nText:  PROJECTS\n1. Firewatch\nTimeFrame\n08/2023 \nLocation\nChennai\nLink to Firewatch\nhttps://firewatch-hosted.vercel.app\nWhat is it about?\na) Developed a website that seamlessly integrates live satellite imagery from NASA satellites, providing real-time data for analysis.\nb) Implemented an advanced system utilizing a pretrained VGG-19 neural network, fine-tuned on a wildfire dataset, resulting in a 20% increase in forest fire detection accuracy through real-time analysis of satellite imagery. \n\nSource:  /kaggle/input/naman-update/resume.txt\nText:  NAMAN NANDA\nProfile \nSoftware Engineering Intern\nPhone Number \n8115700008 \nemail id \nnamannanda5657@gmail.com\nLinkedin link \nhttps://www.linkedin.com/in/naman-nanda-998245221 \nGithub link \nhttps://github.com/nimo-codes\nLocation\nChennai, India\n\nEDUCATION\nBachelor of Technology, Computer Science w/s AIML\nInstitute\nSRM Institute of Science and Technology\nGraduation Date\n2022 - 2026\nCGPA\n9.1/10\nCourse work\nData Structures and Algorithms, Data Analysis, Advanced Calculus, Neural Networks\nEXPERIENCE\n1. Technical Intern\nCompany \nRenault Nissan\nTime Frame \n06/2024 - Present \nLocation\nChennai\nWorking on\na) Engineering RESTful APIs to streamline data exchange between different systems, enhancing the efficiency and reliability of backend services. Leveraged frameworks such as Flask to create robust and scalable API endpoints.\nb) Utilized Postman for comprehensive API testing and am currently learning how to deploy scalable and secure API solutions \n\nSource:  /kaggle/input/naman-update/resume.txt\nText:  4. President\nClub Name\nNEXT GEN AI\nTimeFrame\n08/2022 - Present \nLocation\nSRM University, Chennai\nProjects\na) Led the Next Gen AI Club, honing team leadership and management skills while organizing the university's largest hackathon. \nb) Collaborated with professors on projects, fostering a dynamic environment for coding and machine learning innovation.\n\nSKILLS\n1. Python \n2. CPP \n3. Data Structures and Algorithmns\n4. Tensorflow \n5. Pytorch \n6. Open-CV \n7. Sci-Kit \n8. OS \n9. Linux\n10. ML-OPS \n11. Web Automation \n12. Flask\n13. Rest API \n\nSource:  /kaggle/input/naman-update/resume.txt\nText:  CERTIFICATION\n1. Computer Architecture NPTEL\n2. Programming in JAVA NPTEL\n3. Machine Learning and Deep Learning DeepLearning.AI\n4. Algorithmic Toolbox UC SanDiego (Coursera) \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}